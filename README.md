# Human Pose Estimation

## What is Pose Estimations

Human Pose estimation is an important problem that has enjoyed the attention of the Computer Vision community for the past few decades. It is a crucial step towards understanding people in images and videos This is based on deconvolutional layers added on a ResNet. The model achieves an mAP of 73.7 on a COCO test-dev split. Its pose tracking model achieves an mAP score of 74.6 and a MOTA (Multiple Object Tracking Accuracy) score of 57.8. The authors are from Microsoft Research Asia and the University of Electronic Science and Technology of China.

What is Human Pose Estimation? Human Pose Estimation is defined as the problem of localization of human joints (also known as keypoints - elbows, wrists, etc) in images or videos. It is also defined as the search for a specific pose in space of all articulated poses.


2D Pose Estimation - Estimate a 2D pose (x,y) coordinates for each joint from a RGB image. 3D Pose Estimation - Estimate a 3D pose (x,y,z) coordinates a RGB image.

![pose1](/2.png)

## Challenges with Pose Estimations and Solutions

Why is it hard? Strong articulations, small and barely visible joints, occlusions, clothing, and lighting changes make this a difficult problem.

Classical approaches The classical approach to articulated pose estimation is using the pictorial structures framework. The basic idea here is to represent an object by a collection of "parts" arranged in a deformable configuration (not rigid). A "part" is an appearance template which is matched in an image. Springs show the spatial connections between parts. When parts are parameterized by pixel location and orientation, the resulting structure can model articulation which is very relevant in pose estimation. (A structured prediction task)

The above method, however, comes with the limitation of having a pose model not depending on image data. As a result, research has focused on enriching the representational power of the models. Deformable part models - Yang and Ramanan use a mixture model of parts which expresses complex joint relationships. Deformable part models are a collection of templates arranged in a deformable configuration and each model has global template + part templates. These templates are matched for in an image to recognize/detect an object. The Part-based model can model articulations well. This is however achieved at the cost of limited expressiveness and does not take in global context into account.

Deep Learning based approaches The classical pipeline has its limitations and Pose estimation has been greatly reshaped by CNNs. With the introduction of “DeepPose” by Toshev et al, research on human pose estimation began to shift from classic approaches to Deep Learning. Most of the recent pose estimation systems have universally adopted ConvNets as their main building block, largely replacing hand-crafted features and graphical models; this strategy has yielded drastic improvements on standard benchmarks.

Simple Baselines for Human Pose Estimation and Tracking While the hourglass network uses upsampling to increase the feature map resolution and puts convolutional parameters in other blocks, this method combines them as deconvolutional layers in a very simple way. It was quite surprising to see such a simple architecture perform better than one with skip connections that preserve the information for each resolution.

The method used in this network adds a few deconvolutional layers over the last convolution stage in the ResNet architecture. This structure makes it very easy to generate heatmaps from deep- and low-resolution images. Three deconvolutional layers with batch normalization and ReLU activation are used by default.

The previous approaches work very well but are complex. This work follows the question – how good could a simple method be? And achieved the state-of-the-art at mAP of 73.7% on COCO.

The network structure is quite simple and consists of a ResNet + few deconvolutional layers at the end. (Probably the simplest way to estimate heat maps)

Mean Squared Error (MSE) is used as the loss between the predicted heatmaps and targeted heatmaps. The targeted heatmap H k for joint k is generated by applying a 2D Gaussian centered on the kth joint’s ground truth location with std dev = 1 pixel.



Appendix Common Evaluation Metrics Evaluation metrics are needed to measure the performance of human pose estimation models.

Percentage of Correct Parts - PCP: A limb is considered detected (a correct part) if the distance between the two predicted joint locations and the true limb joint locations is less than half of the limb length (Commonly denoted as PCP@0.5).

It measures the detection rate of limbs. The con is that it penalizes shorter limbs more since shorter limbs have smaller thresholds. Higher the PCP, better the model. Percentage of Correct Key-points - PCK: A detected joint is considered correct if the distance between the predicted and the true joint is within a certain threshold. The threshold can either be:

PCKh@0.5 is when the threshold = 50% of the head bone link PCK@0.2 == Distance between predicted and true joint < 0.2 * torso diameter Sometimes 150 mm is taken as the threshold. Alleviates the shorter limb problem since shorter limbs have smaller torsos and head bone links. PCK is used for 2D and 3D (PCK3D). Again, the higher the better. Percentage of Detected Joints - PDJ: A detected joint is considered correct if the distance between the predicted and the true joint is within a certain fraction of the torso diameter. PDJ@0.2 = distance between predicted and true joint < 0.2 * torso diameter.

## Object Keypoint Similarity (OKS) based mAP:

Commonly used in the COCO keypoints challenge. OKS is the Euclidean distance between the detected keypoint and the corresponding ground truth, To put it simply, OKS plays the same role that IoU plays in object detection. It is calculated from the distance between predicted points and ground truth points normalized by the scale of the person. More info Typically, standard average precision and recall scores are reported in papers:

The targeted heatmap Hˆ k for joint k is generated by applying a 2D gaussian centered on the k th joint’s ground truth location.

One is that we have two different kinds of human boxes, one is from a human detector and the Simple Baselines for Human Pose Estimation and Tracking 5 other are boxes generated from previous frames using optical flow. The second difference is the similarity metric used by the greedy matching algorithm. We propose to use a flow-based pose similarity metric. Combined with these two modifications, we have our enhanced flow-based pose tracking algorithm


## Comparison of Human Pose Estimation Models:

![res2](/res2.png)

![res1](/res1.png)


